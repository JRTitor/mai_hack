{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tqdm\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "import seaborn as sns\n",
    "from parser import *\n",
    "from visualizer import *\n",
    "from ya_loader import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### базовая предложеннная модель"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$f(x_1, x_2, x_3, x_4) = \\hat{y} $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class baseline_model(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.l1 = nn.Linear(4, 8)\n",
    "        self.l2 = nn.Linear(8, 6)\n",
    "        self.l3 = nn.Linear(6, 4)\n",
    "        self.l4 = nn.Linear(4, 3)\n",
    "        self.l5 = nn.Linear(3, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out1 = self.l1(x)\n",
    "        out2 = self.l2(out1)\n",
    "        out3 = F.tanh(self.l3(out2))\n",
    "        out4 = self.l4(out3)\n",
    "        out5 = self.l4(out4)\n",
    "        return out5\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Улучшения модели"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Почему бы не кинуть кэтбуст вместо второго и остальных линейных слоёв, мб он даст лучше метрики, на 4 фичах всё будет плохо, но на 8 мб всё ок должно быть "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Можно сделать датафрейм из с помощью парсера, но для каждой фигуры свой датафрейм, как я понял, и тогда для каждой фигуры своя архитектура, то есть наша работа будет бесполезной"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, optimizer, scheduler, loss_fn, train_loader, val_loader, n_epochs, device):\n",
    "    train_losses = []\n",
    "    val_losses = []\n",
    "\n",
    "    for epoch in tqdm(range(n_epochs)):\n",
    "        model.train()\n",
    "        train_losses_per_epoch = []\n",
    "        for X_batch, y_bathch in (train_loader):\n",
    "            optimizer.zero_grad()\n",
    "            preds = model(X_batch.to(device))\n",
    "            loss = loss_fn(preds, y_bathch.to(device))\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            train_losses_per_epoch.append(loss.item())\n",
    "        scheduler.step()  ### ничего про него я не заметил, пока пусть будет\n",
    "        train_losses.append(np.mean(train_losses_per_epoch))\n",
    "\n",
    "        model.eval()\n",
    "        val_losses_per_epoch = []\n",
    "        with torch.no_grad():\n",
    "            for X_batch, y_bathch in val_loader:\n",
    "                pred = model(X_batch.to(device))\n",
    "                loss = loss_fn(pred, y_bathch.to(device))\n",
    "                val_losses_per_epoch.append(loss.item())\n",
    "\n",
    "        val_losses.append(np.mean(val_losses_per_epoch))\n",
    "    \n",
    "    return train_loader, val_loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(model, test_loader, device):\n",
    "    preds = np.array([])\n",
    "    with torch.no_grad():\n",
    "        for X_batch in test_loader:\n",
    "            pred = model(X_batch.to(device))\n",
    "            np.append(preds, pred.detach().numpy())\n",
    "    return preds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class coords_param(Dataset):\n",
    "    def __init__(self, made_dataset):\n",
    "        self.__lenght = 0\n",
    "        self.data = made_dataset\n",
    "        super().__init__()\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.__lenght\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        return self.data.iloc(index)\n",
    "'''я пока хз какой будет датасет на входе c скорее всего всё совсем не так'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "вообще из того, что есть надо сначала собрать датасет и что-то подумать че и как, щас я вообще хз\n",
    "\n",
    "Короче нам надо как-то датасет собрать в пандасе, щас это всё протс по преколу, я не ебу зачем они нас заставляют ебаться с этим"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### примеры пасера и визуалайзера и лоадера"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### parcer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH_TO_CASE = 'data/princess_luna/0.3M/'\n",
    "END_TIME = '150'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_path = Path(PATH_TO_CASE)\n",
    "time_path = base_path / Path(END_TIME)\n",
    "p_path = time_path / Path('p')\n",
    "p = Ofpp.parse_internal_field(p_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "surface = pressure_field_on_surface(base_path, p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for s in surface[0]['Item2']:\n",
    "    pprint(s)\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### visualizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_slices(base_path, base_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "yadisk_url = 'https://disk.yandex.ru/i/3ywDfjugWiULSQ'\n",
    "print(get_real_direct_link(yadisk_url))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "urllib.request.urlretrieve(get_real_direct_link(yadisk_url), 'data.jpg') "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "                                                        link, path_for_img"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
